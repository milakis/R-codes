{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list=ls())\n",
    "#install.packages(\"matrixStats\")\n",
    "library(\"matrixStats\")\n",
    "require(parallel)\n",
    "#install.packages(\"MASS\")\n",
    "library(MASS)\n",
    "#install.packages(\"glmnet\")\n",
    "library(\"glmnet\")\n",
    "#install.packages(\"pbapply\")\n",
    "library(pbapply)\n",
    "#install.packages(\"stats\")\n",
    "library('stats')\n",
    "#install.packages(\"tseries\")\n",
    "library(\"tseries\")\n",
    "#install.packages(\"xtable\")\n",
    "library(\"xtable\")\n",
    "#install.packages(\"ggplot2\")\n",
    "library(\"ggplot2\")\n",
    "#install.packages(\"dplyr\")\n",
    "library(\"dplyr\")\n",
    "#install.packages(\"tidyr\")\n",
    "library(\"tidyr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of shrinkage methods in macroeconomic forecasting\n",
    "\n",
    "The project by [Liudmila Kiseleva](https://github.com/milakis) for the course [Computational Statistics](https://github.com/ljanys/CompStat/).\n",
    "\n",
    "Based on the paper Smeekes, S., and Wijler, E. (2018). [Macroeconomic forecasting using penalized regression methods](https://www.sciencedirect.com/science/article/pii/S0169207018300074). International Journal of Forecasting, 34(3), 408-430."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Forecasting macroeconomic outcomes by the nonstructural methods appears to be not an easy task: macroeconomic data tends to be high-dimensional. Traditionally, shrinkage methods are considered to be a solution for performing forecasts in a high-dimensional setting with many potential predictors. I focus on ridge and lasso regressions. First, I describe their theoretical properties and explain their differences. Second, I simulate realistic macroeconomic time series to evaluate ridge and lasso performance in the sparse/abundant models; in the models with different number of predictors; in the models with cross-sectional and serial correlation. Finally, I apply ridge and lasso regressions to the [FRED Monthly Database for Macroeconomic Research](https://research.stlouisfed.org/econ/mccracken/fred-databases/) to compare their performance for few selected macroeconomic variables. I obtain predictable result: ridge and lasso tend to outperform each other when the Data Generation Process for the series differs. Therefore, I conclude that an optimal strategy for macroeconomists would be not to choose one shrinkage method to perform the forecast; but to combine few methods and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Introduction](#introduction)\n",
    "* [2. Shrinkage methods description](#chapter2)\n",
    "    * [2.1 Motivation for shrinkage methods in macroeconomic forecasting](#section_2_1) \n",
    "    * [2.2 Theoretical properties of the OLS estimator](#section_2_2)\n",
    "    * [2.2 Theoretical properties of the ridge estimator](#section_2_3)\n",
    "    * [2.2 Theoretical properties of the lasso estimator](#section_2_4)\n",
    "* [3. Simulation study](#chapter3)\n",
    "    * [3.1 Data simulation and estimation algorithms](#section_3_1) \n",
    "    * [3.2 Demonstration of one trial](#section_3_2)\n",
    "    * [3.3 Sparsity and number of predictors effects](#section_3_3)\n",
    "    * [3.4 Cross-sectional and serial correlation effects](#section_3_4)\n",
    "* [4. Empirical application](#chapter4)\n",
    "    * [4.1 Data preparation](#section_4_1)\n",
    "    * [4.2 Application](#section_4_2)\n",
    "* [5. Conclusion](#chapter5)\n",
    "* [6. References](#chapter6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasting macroeconomic variables by the nonstructural methods appears to be not an easy task: macroeconomic data tends to be high-dimensional. That happens because data availability is naturally limited by time; however, the number of potential predictors might be notoriously high. High dimensionality leads to a lot of variability in the fit or even to the infinite variance; high variance applies that small changes in the data can result in large changes in the estimate. Therefore, the forecast might not yield accurate estimates of the response on new observations that were not part of the original data set. Traditionally, regularization methods are considered to be a solution for performing forecasts in the high-dimensional setting with many potential predictors. I choose one of the group of regularization methods - shrinkage methods - to demonstrate their ability to solve curse of dimensionality issue and to compare their performance in different settings.\n",
    "\n",
    "In my project I focus on two shrinkage methods: ridge and lasso regressions. Their main idea is to regularize the coefficients with specific penalty functions to control the variance. Penalty functions force the variance of the coefficient estimates to decrease towards zero at the cost of larger bias of the estimates. The difference between ridge and lasso lies in the specification of the penalty functions: the former uses $l_2$-norm and the later - $l_1$-norm. With the help of the $l_2$-norm ridge regression shrinks the coefficients towards zero but never sets them exactly to zero. On the other hand, with the $l_1$-norm lasso sets some coefficients exactly equal to zero; hence, lasso also performs the model selection for us. \n",
    "\n",
    "This difference in approaches justifies the fact that ridge and lasso outperform each other in the settings with various Data Generation Processes (DGP). First, we would expect that lasso will show better performance when many of the true coefficients in the model are, in fact, equal to zero. I call it sparse model. On the opposite, ridge is expected to perform better in the abundant model when many predictors, indeed, have some effect on the response variable. I demonstrate this in my simulation study based on Smeekes and Wijler (2018). I generate the data with the purpose to resemble the realistic macroeconomic times series. Then I vary the number of predictors of which true coefficients are equal to zero. The performance of each method is evaluated by the test mean square error (MSE). I obtain the predictable result that ridge outperforms lasso in the abundant model and lasso outperforms ridge in the sparse model. I do this for the different number of potential predictors to show the curse of dimensionality in practice: the variance is appeared to be proportional to the number of variables included in the model. Another interesting fact is that the variance tends to be larger in the abundant model. It can be explained by the potential multicolinearity between variables. Since a large part of variables has an effect on reponse, it is challenging to identify the effect between relevant and irrelevant  variables. To evaluate this statement I manually introduce multicolinearity to the data. I observe similar picture: the MSE substantially increases in the abundant mode;l and ridge/lasso is a favorable method in the abundant/sparse model. Finally, I add serially correlated errors to the model to mimic the time series data structure. Serial correlation in the error terms might signal that the lagged version of the dependant variable is missed in the specification. I do not find any significant effect on the difference in performance between ridge and lasso; however, the variance for all specifications tends to be underestimated. \n",
    "\n",
    "To illustrate how ridge and lasso will perform in empirical setting I use [FRED Monthly Database for Macroeconomic Research](https://research.stlouisfed.org/econ/mccracken/fred-databases/). The database presents 135 variables on a monthly basis beginning from 1959. I select four response variables: Total Industrial Production, Civilian Employment, Real Personal Consumption Expenditures, and Effective Federal Funds Rate. Consequently, the other variables in the database as well as the lags of a response variables would be potential predictors. In the estimation I follow the rolling window approach as in Smeekes and Wijler (2018). It means that an initial in-sample period covering 10 years of monthly observations is used to estimate the models by which to obtain the first out-of-sample prediction. For each new prediction, we keep the length of the in-sample period fixed and move the estimation sample forward by one period. The number of optimal lags is determined by BIC. I apply the forecasting horizon of six months. As the result, I find that ridge produces lower MSE for two response variables and lasso - for the other two reponse variables. That means that the DGP of the series in the macroeconomic dataset might differ; therefore, there is no universal shrinkage method which we can apply to macroeconomic data and which will outperform the others in any ocassion.\n",
    "\n",
    "In section 2 I explain why I choose to apply shrinkage methods in macroeconomic forecasting. I also present the theoretical properties of the ridge and lasso regressions in comparison to the OLS. In section 3 I describe how I generate data and implement the simulation study. In section 4 I perform the empirical application of ridge and lasso with macroeconomic dataset. I conclude in section 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Shrinkage methods description  <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I explain why I choose to apply shrinkage methods in a high-dimensional times series data setting and provide a short literature review on the topic. Then I describe theoretical properties of the methods. For this I begin with the classical properties of the OLS estimator. Then I report how these properties can be expanded with the penalty functions used in ridge and lasso estimation. Detailed representation of the properties allows me to demonstrate how shrinkage methods ressolve the issues induced by the DGP and illustrate under what conditions one method can outperform the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Motivation for shrinkage methods in macroeconomic forecasting**  <a class=\"anchor\" id=\"section_2_1\"></a>\n",
    "\n",
    "The macroeconomic forecasting literature can be divided into two large parts: structural and nonstructural forecasting methods.Structural methods interpret economic data through the lens of economic theory. In particular, economic theory guides a researcher in developing mathematical statements about how a variable of interest is related to a set of \"explanatory\" variables. These economic assumptions define an empirical model that is capable of predicting possible observable outcomes. Nonstructural methods, on the other hand, rely on economic theory little. They attempt to exploit the reduced-form correlations in observed macroeconomic time series and forecast output variables on the grounds of statistical knowledge. In my project I focus my attention on the nonstructural methods of forecasting; in particular, on the ability of statistical learning techniques to predict macroeconomic outcomes.\n",
    "\n",
    "Statistical learning theory includes regression, classification, regularization, tree based and the other groups of forecasting methods. The choice of a specific method depends on few factors: on the data structure; on the goal a researcher pursues, for example, interpretability of a forecast; and on the assumption of the underlying DGP of the dataset of interest. Refering to the data structure, forecasting macroeconomic variables appears to be not an easy task: the datasets tend to be presented in a high-dimensional times series setting. The reason for high dimensionality lies in the natural limit of the data availability back in time; for instance, some of the most frequently used modern macroeconomic monthly databases start in 1959 (Stock and Watson (2014), McCracken and Ng (2015)). At the same time, the number of potential predictors of business cycle fluctuations might be notoriously high. Therefore, the number of predictors can be close/equal to or more than the number of observations. The former leads to a lot of variability in the fit; the later - to a non-unique least squares estimates and the infinite variance. The high variance might be not in favor while forecasting because small changes in the data can result in large changes in the estimate.  Hence, the forecast obtained will not yield accurate estimates of the response on new observations that were not part of the original data set. The second factor in choosing a method is how easily the forecasted result is interpretable. Even though the number of potential predictors can be large, only some of the variables might be associated with the response. Including irrelevant variables results in unnecesary complexity of the model and, hence, in difficulty with its interpretation. \n",
    "\n",
    "Traditionally, regularization methods are considered to be a solution for performing forecasts in the high-dimensional setting with many potential predictors. This group of techniques improves simple linear regression model by replacing least square fitting with the alternative fitting procedures. Specifically, subset selection approach involves identifying the subset of input variables that are related to a response and runnig a regression on a reduced set of variables. Penalized methods, such as ridge and lasso regressions, shrink the estimated coefficients towards zero what has an effect of variance reduction and, depending on the method, variable selection. Dimension reduction approach computes $M$ linear combinations, or projections, of $p$ predictors, where $M < p$, and uses these projections in the least squares regression. Hence, regularization methods propose more restrictive procedure for macroeconomic forecasting with the higher level of prediction accuracy and lower variance compared to the simple least squares regression or tree based methods.  \n",
    "\n",
    "Subset selection methods, in particular, backward and forward stepwise regressions, do not appear to be popular among macroeconomists to produce forecasts for few reasons. First, stepwise algorithms appear to be ‘greedy’: it is not guaranteed that best possible model containing a subset of the predictors would be found. Second, they perform what is known as ‘hard thresholding’: regressor set selected from the available predictors may disagree with the one chosen when the number of available predictors is increased or decreased slightly. In other words, hard thresholding is sensitive to the small changes in the data. For these reasons I don't concentrate on subset selection methods in my project. Dimension reduction methods principal component analysis (PCA) and factor analysis, on the other hand, became the workhorse methods for macroeconomic forecasting. Factor models were demonstrated to perform prominently by Stock and Watson (1999) and Stock and Watson (2002). PCA has been the preferable way of factor model estimations; rigorous illustrations can be found in Bai and Ng (2002), Bai (2003), and Bai and Ng (2006). Consequently, dimension reduction methods is the huge topic for the research; I will leave it for now because of the limited capacity of my project.\n",
    "\n",
    "In my work I focus on the shrinkage methods; specifically, on the ridge and lasso regressions. Ridge regression was introduced by Hoerl and Kennard (1970). The main idea of ridge is to penalize the regression coefficients to reduce the variance at the cost of estimator bias using $l_2$-norm as a penalty function. The Least Absolute Shrinkage and Selection Operator (lasso) was proposed by Tibshirani (1996). It uses $l_1$-norm penalty function which allows to shrink some of the regression coefficients exactly to zero and, therefore, it additionally performs variable selection. Since the time of the first publications ridge and lasso became a popular tool for estimation in medicine and biological studies (Jain (1985), Ogutu et al. (2012), Vlaming and Groenen (2015), Goebl et al. (2015), Zhang et al. (2017)); agriculture (Conniffe et al. (1976), Pimentel et al. (2007), Jamal (2007), Singh (2019), Johnston (2019)); sociology (Bucca and Urbina (2017), Beard (2019), Molina and Garip (2019)); and in the other disciplines including various fields in economics (Huang and Mintz (1990), Schneider and Wagner (2008), Jean et al. (2016), Mullainathan and Spiess (2017),  McKenzie and  Sansone (2019)).\n",
    "\n",
    "In recent macroeconomic forecasting literature shrinkage methods got a lot of attention in various time series high-dimensional settings.  The authors attempt to assess the properties of ridge and lasso in autoregressive (AR) and vector autoregressive (VAR) models; in stationary and non-stationary processes with Gaussian and non-Gaussian errors. For instance, De Mol et al. (2008) compare PCA with penalized regressions in a forecasting model without lags and with Gaussian errors. Wang et al. (2007) and Hsu et al. (2008) assess subset selection via the lasso in AR and VAR models. Kim and Swanson (2014) apply data reduction methods in an empirical setting. Kock and Callot (2015) establish non-asymptotic oracle inequalities for the prediction error in stationary VAR. Basu and Michailidis (2015) apply regularized estimation in stochastic regression with serially correlated errors and in VAR models. Medeiros and Mendes (2016) study the asymptotic properties of the lasso when the errors are non-Gaussian and conditionally heteroskedastic. The paper of my interest by Smeekes and Wijler (2018) evaluates the performance of shrinkage methods under different settings: in stationary processes with serially corrrelated and not correlated errors; with increasing number of predictors; with non-stationary and cointegrated variables; in an empirical setting with AR terms. I choose some of these specifications which I consider to be relevant and apply them in my simulation and empirical studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Theoretical properties of the OLS estimator** <a class=\"anchor\" id=\"section_2_2\"></a>\n",
    "\n",
    "Shrinkage methods help to solve the problem of high variance in high-dimensional data. However, the performance of each method depends on the assumed DGP of a dataset of interest. To show how ridge and lasso lower the variance and in what setting each of the method might be favorable, I start with the theoretical properties of the OLS estimator. I expand them for ridge and lasso in the next sub-sections.\n",
    "\n",
    "Consider the linear regression model in the form:\n",
    "\n",
    "$$Y = X \\beta +\\epsilon,$$\n",
    "\n",
    "where:\n",
    "- $Y = (y_1,...,y_n)^T$ is a vector of $n$ responses\n",
    "- $X = (x'_1,...,x'_n)^T$ is a $n \\times p$ matrix of predictors of rank $p (\\leq n)$\n",
    "- $\\beta = (\\beta_1,...,\\beta_p)^T$ is a $p$ vector of coefficients\n",
    "- $\\epsilon$ is a $n$ vector of independently and identically distributed (i.i.d.) error terms, $E(\\epsilon)=0$ and $E(\\epsilon \\epsilon^T) = \\sigma^2 I_n$\n",
    "\n",
    "The least square estimator of $\\beta$ can be obtained by minimizing the residual sum of squares (RSS):\n",
    "\n",
    "$$\\mathop{min}_{\\textbf{$\\beta$}}((Y - X \\beta)^T (Y - X \\beta))$$\n",
    "\n",
    "Solving it with respect to $\\beta$ gives:\n",
    "\n",
    "$$\\hat{\\beta}^{ols} = (X^T X)^{-1} X^T Y$$ (1)\n",
    "\n",
    "Additionally, OLS estimator is unbiased: \n",
    "\n",
    "$$E(\\hat{\\beta}^{ols}) = E((X^T X)^{-1} X^T Y) = E(\\beta + (X^T X)^{-1} X^T \\epsilon) = \\beta$$, \n",
    "\n",
    "and its variance–covariance matrix is equal to:\n",
    "\n",
    "$$Var(\\hat{\\beta}^{ols}) = E((\\hat{\\beta}^{ols} - \\beta)(\\hat{\\beta}^{ols} - \\beta)^T) = E((X^T X)^{-1} X^T \\epsilon \\epsilon^T X (X^T X)^{-1}) = \\sigma^2 (X^T X)^{-1}$$ (2).\n",
    "\n",
    "From (1) we can see that OLS estimator is only definied if $(X^T X)^{-1}$ exist, therefore, matrix $X^T X$ should be full-rank. Otherwise, the matrix is invertible and its determinant is equal to zero. This is the case when the columns of $X$ can be written as a linear combination of the other columns and, hence, the covariates are perfectly multicolinear. If we try to compute the variance from (2), we face a division-by-zero problem: we divide $\\sigma^2$ by zero and, as a consequence, the variances of the regression coefficients (the diagonal elements of $Var(\\hat{\\beta}^{ols})$) go to infinity. This case mostly occurs in a high-dimensional data in which the number of covariates $p$ exceeds the number of observations $n$. \n",
    "\n",
    "If one of the regressors is highly correlated with the other regressors, then the regression suffers from multicollinearity, although the multicollinearity is not perfect. In such a case the matrix is full-rank, but it is not very far from being rank-deficient. Continuing with the division-by-zero analogy above, when multicollinearity is not perfect, we are dividing $\\sigma^2$ in equation (2) by a number that is very small, so that the variances of the regression coefficients are very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Theoretical properties of the ridge estimator** <a class=\"anchor\" id=\"section_2_3\"></a>\n",
    "\n",
    "We have seen that, if the data is high-dimensional and multicolinear, then the matrix $(X^T X)^{-1}$ from the equation (1) can be a very small number or zero. Therefore, the coefficients $\\hat{\\beta}^{ols}$ can explode (become large). Here lies the main idea behind ridge regression: to control variance, we might constraint or regularize the coefficients. Hence, the minimization of the penalized residual sum of squares (PRSS) is equivalent to solving the following convex optimization problem:\n",
    "\n",
    "$$\\mathop{min}_{\\textbf{$\\beta$}}(Y - X \\beta)^T (Y - X \\beta)$$\n",
    "\n",
    "subject to the $$\\sum_{j=1}^{p} \\beta_j^2 \\leq t$$ (3)\n",
    "\n",
    "for some positive value $t$. $||\\beta||_2 = \\sum_{j=1}^{p} \\beta_j^2$ is also called $l_2$-norm. \n",
    "\n",
    "Two important assumptions:\n",
    "- $X$ is assumed to be standardized (zero mean, unit variance)\n",
    "- $Y$ is assumed to be centered\n",
    "\n",
    "We solve the penalized residual sum of squares:\n",
    "\n",
    "$$PRSS(\\beta)_{l_2} = (Y - X \\beta)^T (Y - X \\beta) + \\lambda \\sum_{j=1}^{p} \\beta_j^2 $$\n",
    "\n",
    "$\\lambda \\geq 0$ is called tuning parameter and $\\lambda \\sum_{j=1}^{p} \\beta_j^2$ is shrinkage penalty term. Notice that the intercept $\\beta_0$ is not included to the penalty term: we want to shrink the estimated coefficients of the predictors but not the intercept, which is simply a measure of the mean value of the response.\n",
    "\n",
    "That gives the following ridge estimator:\n",
    "\n",
    "$$\\hat{\\beta}^{ridge} = (X^T X + \\lambda I_p)^{-1} X^T Y$$ \n",
    "(3.1)\n",
    "\n",
    "Since we are adding a positive constant to the diagonal of $X^T X$, we are, in general, producing an invertible\n",
    "matrix, $X^T X + \\lambda I_p$, even if $X^T X$ is singular. \n",
    "\n",
    "The ridge regression estimator is related to the classical OLS estimator in the following manner:\n",
    "\n",
    "$$\\hat{\\beta}^{ridge} = (X^T X + \\lambda I_p)^{-1} X^T Y = (I_p + \\lambda (X^T X)^{-1})(X^T X)^{-1} X^T Y = (I_p + \\lambda (X^T X)^{-1}) \\hat{\\beta}^{ols} $$ \n",
    "\n",
    "Ridge estimator is biased estimator of the true parameter $\\beta$ if $\\lambda \\neq 0$:\n",
    "\n",
    "$$E(\\hat{\\beta}^{ridge}) = E((I_p + \\lambda (X^T X)^{-1}) \\hat{\\beta}^{ols}) = (I_p + \\lambda (X^T X)^{-1}) \\beta \\neq \\beta$$ (4)\n",
    "\n",
    "We can see from the equation (4) that  the bias of the ridge estimator is proportional to $\\lambda$. That is, the larger is $\\lambda$, the larger is the bias of the ridge estimator with respect to $\\beta$.\n",
    "\n",
    "The variance of the ridge estimator is:\n",
    "\n",
    "$$Var(\\hat{\\beta}^{ridge}) = E(\\hat{\\beta}^{ridge} - \\beta)(\\hat{\\beta}^{ridge} - \\beta)^T) = E((X^T X + \\lambda I_p)^{-1} X^T \\epsilon \\epsilon^T X (X^T X + \\lambda I_p)^{-1}) = \\sigma^2 W (X^T X)^{-1} W^T,$$ (5).\n",
    "\n",
    "where $W = (X^T X + \\lambda I_p)^{-1} X^T X$. \n",
    "\n",
    "The variance of the ridge regression estimator vanishes as $\\lambda$ tends to infinity:\n",
    "\n",
    "$$\\lim_{\\lambda\\to\\infty} Var(\\hat{\\beta}^{ridge}) = \\lim_{\\lambda\\to\\infty} \\sigma^2 W (X^T X)^{-1} W^T = 0_{pp}$$\n",
    "\n",
    "*Hence, the variance of the ridge coefficient estimates decreases towards zero and the bias becomes larger as the penalty parameter becomes large.*\n",
    "\n",
    "The next question is whether such $\\lambda$ exist so that the ridge regression estimator may outperform the OLS estimator. Theorem 2 by Theobald (1974) provides the proof using the concept of the MSE. The MSE of any estimator of a parameter $\\theta$ can be presented as the sum of the variance of the estimator and the squared bias of the estimator: $MSE(\\hat{\\theta}) = Var(\\hat{\\theta}) + [Bias(\\hat{\\theta})]^2$. The equation implies that in the case of unbiased estimators, the MSE and variance are equivalent. \n",
    "\n",
    "Theorem 2 says that, if the condition \n",
    "\n",
    "$$\\lambda < 2 \\sigma^2 ((\\beta^{ridge})^T \\beta^{ridge})^{-1}$$\n",
    "(5)\n",
    "\n",
    "is satisfied, then \n",
    "\n",
    "$$MSE(\\hat{\\beta}^{ridge}(\\lambda)) < MSE(\\hat{\\beta}^{ridge}(0)) = MSE(\\hat{\\beta}^{ridge})$$. \n",
    "\n",
    "Theorem illustrates that the ridge regression estimator strikes a balance between the bias and variance: for small $\\lambda$ the variance of the ridge estimator dominates the MSE and the ridge estimator is close to the unbiased OLS estimator. For large $\\lambda$ the variance vanishes and the bias dominates the MSE. Also, according to the equation (5), the optimal value of $\\lambda$ depends on the quantities $\\beta$ and $\\sigma^2$; they are unknown in practice. Then, the penalty parameter is chosen in a data-driven fashion by means of cross-validation or information criterion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Theoretical properties of the lasso estimator** <a class=\"anchor\" id=\"section_2_4\"></a>\n",
    "\n",
    "Ridge regression helps to reduce the variance of the estimator. However, it will not set any of the ridge coefficients exactly to zero: from the equation (3.1) matrix $X^T X$ is positive semi-definite  and no increase in non-negative $\\lambda$ will drive the estimator to zero. Hence, ridge regression will include all the predictors to the final model. It is a disadvantage of ridge regression because while we are working with complex models we may want to produce sparse solution for better interpretability of the final result. The lasso provides this kind of solution: for large enough tuning parameter $\\lambda$ it sets some coefficients exactly equal to zero. So then the lasso also performs the model selection for us. \n",
    "\n",
    "Lasso convex optimization problem looks similar to the ridge problem: \n",
    "\n",
    "$$\\mathop{min}_{\\textbf{$\\beta$}}(Y - X \\beta)^T (Y - X \\beta)$$\n",
    "\n",
    "subject to the $$\\sum_{j=1}^{p} |\\beta_j| \\leq t$$ \n",
    "\n",
    "Therefore, the PRSS is:\n",
    "\n",
    "$$PRSS(\\beta)_{l_1} = (Y - X \\beta)^T (Y - X \\beta) + \\lambda \\sum_{j=1}^{p} |\\beta_j| $$\n",
    "\n",
    "You can see that the lasso penalty term differs from the ridge penalty term. $||\\beta||_1 = \\sum_{j=1}^{p} |\\beta_j|$ is called $l_1$-norm. \n",
    "\n",
    "Contrary to ridge regression, the lasso does not admit a closed-form solution. The $l_1$-penalty makes the\n",
    "solution non-linear because the absolute value is not differentiable. The above constrained minimization is a quadratic programming problem, whose solution can be efficiently approximated. Tibshirani (1996) does that in the original paper and depicts geometrically why ridge and lasso shrink the coefficients to zero differently for the two parameters :\n",
    "\n",
    "![Alt](images/Tibshirani.png)\n",
    "\n",
    "On the first picture we see lasso regression and on the second - ridge regression. The residual sum of squares has elliptical contours, centered at the full least squares estimate. The constraint region for ridge regression is the disk and for lasso is the diamond. The solution is the first place that the contours touch the disk or the diamond. For the ridge regression there are no corners for the contours to hit and, hence, no zero solutions. Unlike the disk, the diamond has corners; if the solution occurs at a corner, then it has one parameter $\\beta_j$ equal to zero. If there are more than two parameters, the diamond becomes a rhomboid, and has many corners, flat edges and faces; there are many more opportunities for the estimated parameters to be zero.\n",
    "\n",
    "There exists large literature on the theoretical properties of lasso and the analytical solution in different contexts such as Buhlmann and van de Geer (2011), Tibshirani and Taylor (2011), Tibshirani (2012), Wieringen (2020a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simulation study <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Data simulation and estimation algorithms** <a class=\"anchor\" id=\"section_3_1\"></a>\n",
    "\n",
    "I simulate different specifications of the datasets based on the framework by Smeekes and Wijler (2018) assuming that these DGPs might be the ones to produce the FRED database. Simulation of a typical macroeconomic dataset will differ from the cross-sectional simulation because the observations here will have time index. That results in possible correlation between observations which is common for the time series data. Moreover, some of the procedures to work with data applied in a cross-sectional setting should be corrected in a times series setting. For example, traditional $k$-fold cross-validation (CV) is replaced by the time series CV to keep the time structure of the data intact which I describe further in the section. I focus on stationary times series, and in the empirical application I correct the time series for stationarity. Smeekes and Wijler (2018) in their original paper also simulate the non-stationary and cointegrated variables. \n",
    "\n",
    "I generate stationary processes where the dependent variable depends on observable explanatory variables and a possibly autoregressive error term:\n",
    "\n",
    "$$y_{t+1} = x'_t \\beta_x + \\epsilon_{t+1}$$\n",
    "$$(1 - \\alpha L) \\epsilon_{t+1} = v_{t+1},$$\n",
    "\n",
    "where $x_t \\sim \\mathcal{N}(0,\\sum_N)$, \n",
    "$ \\sum_N = \n",
    "\\begin{bmatrix} \n",
    "1 & ... & p^{|j-i|} \\\\\n",
    "... & ... & ...\\\\\n",
    "p^{|i-j|} & ... & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "$ and $v_{t+1} \\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "Further assumptions about the variables and their distribution depend on the specification of the dataset:\n",
    "- Criteria 1: sparsity. From the section 2 we know that ridge and lasso regressions are applied to mitigate high variance which appears because of possible multicolinearity in the data. However, the efficiency of the methods might differ for the different degrees of sparsity in the model. Since the lasso shrinks some of the coefficients exactly to zero and ridge shrinks the coeficients toward zero but never sets them exactly to zero, we would expect that the lasso will perform better when some of the true coefficients are zero and ridge, on the opposite, when the true coefficients are not zero. Therefore, I simulate two specifications of the dataset with the different degrees of sparsity in the coefficients. In the first one five coefficients are non-zero and then $\\beta_x = (i'_5,0'_{N-5})'$ where $i_5$ is a $(5 \\times 1)$ vector of ones, $0_{N-5}$ is a $((N-5) \\times 1)$ vector of zeros, and $N$ is the number of potential predictors included to the model. In the second specification $\\beta = (i'_{N*3/5},0'_{N*2/5})'$ where $i'_{N*3/5}$ is a $(N*3/5 \\times 1)$ vector of ones and $0_{N*2/5}$ is a $(N*2/5 \\times 1)$ vector of zeros.\n",
    "- Criteria 2: number of predictors. When the number of variables in the candidate set  is large relative to the number of available observations, modelling the dependent variable is likely to result in a large forecasting variance. For example, assuming the explanatory variables follow a Gaussian distribution, Stock and Watson (2006) show that the OLS forecast is normally distributed with a variance proportional to the number of variables included in the model divided by the total number of available observations. Therefore, I apply ols, ridge and lasso regressions to the number of predictors $N =10,50,100$. \n",
    "- Criteria 3: cross-sectional correlation. The presence of multicollinearity in the data, especially between relevant and irrelevant variables, leads to inconsistencies in the selection of the correct variables. We see this effect when we change the sparsity of the model. Additionally, I manually add multicolinearity to the regressors in both sparse and abundant model. For this I change the degree of cross-sectional correlation varying $p$ in the matrix $\\sum_N$. \n",
    "- Criteria 4: serial correlation. It is induced to the simulation to mimic the time series data structure. Serial correlation in the error terms might signal that the lagged version of the dependant variable is missed in the specification. I add serial correlation to the model by varying $\\alpha$. \n",
    "\n",
    "For each specification I generate $100$ observations to the $T = 99$ of which I apply the lasso and ridge regressions. To choose the tuning parameter I generate $(100 \\times 1)$ grid of $\\lambda$-values and select the optimal value by the time series CV as in Hyndman and Athanasopoulos (2018). Time series CV is performed by reserving the first part of the sample to estimate the model under various settings of the tuning parameters after which the resulting models’ fit are compared in a pseudo out-of-sample evaluation. As in the original paper by Smeekes and Wijler (2018) I adopt the threshold $c_T = (\\frac{2}{3} \\times T)$ and let $X_{cT} = (x_1,...,x_{cT})$. For each value of the tuning parameter, say, $\\lambda_j$ for $j \\in J = \\{1,...,100\\}$, the model is estimated on $X_{cT}$ to obtain the coefficient vector $\\hat{\\beta}(\\lambda_j)$. Then a pseudo out-of-sample MSE is calculated as $MSE(\\lambda_j) = \\frac{1}{T - c_T} \\sum_{t = c_T +1}^{T}(y_{t+1} - x'_t \\hat{\\beta}(\\lambda_j))^2$. The final tuning parameter is chosen as $\\hat{\\lambda} = \\mathop{arg min}_{\\textbf{$\\lambda_j$}} MSE(\\lambda_j)$. Then I estimate training data with a chosen value of $\\lambda$ and obtain the forecast $\\hat{y}_{T+1|T} = x'_{T} \\hat{\\beta}_x$ with the test observation. I repeat this procedure over $\\Gamma = 1000$ trials . The forecast performance of each specification $i$ is evaluated by the test MSE: $MSE_i = \\frac{1}{\\Gamma} \\sum_{\\gamma=1}^{\\Gamma} (y^i_{\\gamma,T+1} - \\hat{y}^i_{\\gamma,T+1})^2$. Finally, I report the MSE of the lasso, ridge and OLS regressions relative to the optimal, though infeasible, OLS oracle MSE of the sparse model. OLS oracle is a method which forecasts the dependent variable by applying OLS to the relevant variables only. I also report the average number of variables selected by each method.\n",
    "\n",
    "These functions are used for data generation, estimation and repeating this procedure for $\\Gamma$ trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DGP <- function(rho=0, alpha=0, obs=100, vars=10, mu=rnorm(vars,0,1),stdv=runif(vars,0.001,1), spar=T){\n",
    "    \n",
    "  # For one trial this function generates the data with the following inputs:\n",
    "  # rho is an indicator of cross-sectional correlation\n",
    "  # alpha is an indicator of serial correlation in the error terms\n",
    "  # obs is a number of observations (periods)\n",
    "  # vars is a number of potential predictos\n",
    "  # mu is a vector of means of potential predictors\n",
    "  # stdv is a vector of standard deviations of potential predictors\n",
    "  # spar is an indicator of sparsity in the model\n",
    "    \n",
    "  correlations <- exp(log(rho)*abs(matrix(rep(seq(1,vars),vars),vars,vars)\n",
    "                                   -t(matrix(rep(seq(1,vars),vars),vars,vars))))\n",
    "  #transform the correlation matrix into the covariance matrix\n",
    "  if(rho==0){\n",
    "    sigma <- diag(stdv)%*%diag(stdv)\n",
    "  }else{\n",
    "    sigma <- diag(stdv)%*%correlations%*%diag(stdv)\n",
    "  }\n",
    "  \n",
    "  x <- mvrnorm(obs,mu,sigma)\n",
    "  #randomize the order to avoid a clustering of correlation in neighbouring variables\n",
    "  x <- x[,sample(1:ncol(x),ncol(x))]\n",
    "  \n",
    "  if(spar==T){\n",
    "    beta <- c(rep(1, 5), rep(0, vars-5))\n",
    "  }else{\n",
    "    beta <- c(rep(1, vars*3/5), rep(0, vars*2/5))\n",
    "  }\n",
    "  \n",
    "  u <- rnorm(obs)\n",
    "  epsilon <-vector()\n",
    "  epsilon[1] <- u[1]\n",
    "  for(i in 2:obs){\n",
    "    epsilon[i] = alpha * epsilon[i-1] + u[i]\n",
    "  }\n",
    "  \n",
    "  #DGP\n",
    "  y <- x%*%beta + epsilon\n",
    "  data<-list(y=y,x=x,coef=beta)\n",
    "  data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "find.MSE <- function(x, y, coef, lambda.grid=lambda.grid){\n",
    "    \n",
    "    # For one trial this function:\n",
    "    # divides x and y to training and test observations including oracle samples; \n",
    "    # divides training data to sample and out-of-sample observations; \n",
    "    # derives ridge and lasso coefficients for each lambda on grid using sample data;\n",
    "    # calculates the MSE of forecast for each lambda using out-of-sample data;\n",
    "    # chooses optimal lambda by the minimal MSE;\n",
    "    # derives ridge and lasso coefficients for optimal lambda using training data, also ols coefficients;\n",
    "    # identifies the number of selected predictors for each method;\n",
    "    # calculates the MSE of forecast using test data for each method.\n",
    "\n",
    "    x.train <- x[1:(nrow(x)-1),]\n",
    "    y.train <- y[1:(nrow(y)-1),]\n",
    "    x.test <- x[nrow(x),]\n",
    "    y.test <- y[nrow(y),]\n",
    "    x.train.oracle <- x.train[,(1:sum(coef))]\n",
    "    x.test.oracle <- x.test[(1:sum(coef))]\n",
    "    x.sample <- scale(x.train[1:(2/3*nrow(x.train)),])\n",
    "    y.sample <- scale(y.train[1:(2/3*length(y.train))])\n",
    "    x.outsample <- x.train[((2/3*nrow(x.train)+1):nrow(x.train)),]\n",
    "    y.outsample <- y.train[((2/3*length(y.train)+1):length(y.train))]\n",
    "\n",
    "    MSE.lambda.ridge <- c()\n",
    "    MSE.lambda.lasso <- c()\n",
    "    for (j in 1:length(lambda.grid)){\n",
    "        lam <- lambda.grid[j]\n",
    "        ridge <- glmnet(x.sample, y.sample, alpha=0, lambda=lam, intercept=FALSE)\n",
    "        lasso <- glmnet(x.sample, y.sample, alpha=1, lambda=lam, intercept=FALSE)\n",
    "        SE.lambda.ridge <- c()\n",
    "        SE.lambda.lasso <- c()\n",
    "        for (i in 1:length(y.outsample)){\n",
    "            SE.lambda.ridge[i] <- (y.outsample[i] - sum(coef(ridge)[2:(ncol(x)+1)]*x.outsample[i,]))^2\n",
    "            SE.lambda.lasso[i] <- (y.outsample[i] - sum(coef(lasso)[2:(ncol(x)+1)]*x.outsample[i,]))^2\n",
    "        }\n",
    "        MSE.lambda.ridge[j] <- sum(SE.lambda.ridge)/length(y.outsample)\n",
    "        MSE.lambda.lasso[j] <- sum(SE.lambda.lasso)/length(y.outsample)\n",
    "    }\n",
    "    lambda.ridge <- lambda.grid[which.min(MSE.lambda.ridge)]\n",
    "    lambda.lasso <- lambda.grid[which.min(MSE.lambda.lasso)]\n",
    "\n",
    "    lasso <- glmnet(scale(x.train), scale(y.train), alpha=1, lambda=lambda.lasso, intercept=FALSE)\n",
    "    var.lasso <- sum(coef(lasso)[(2:(ncol(x)+1))] != 0)\n",
    "    ridge <- glmnet(scale(x.train), scale(y.train), alpha=0, lambda=lambda.ridge, intercept=FALSE)\n",
    "    var.ridge <- sum(coef(ridge)[(2:(ncol(x)+1))] != 0)\n",
    "    ols.oracle <- solve(t(scale(x.train.oracle))%*%scale(x.train.oracle))%*%(t(scale(x.train.oracle))\n",
    "                                                                             %*%scale(y.train))\n",
    "    \n",
    "    MSE.ridge.error <- (y.test - sum(coef(ridge)[2:(ncol(x)+1)]*x.test))^2\n",
    "    MSE.lasso.error <- (y.test - sum(coef(lasso)[2:(ncol(x)+1)]*x.test))^2\n",
    "    MSE.ols.oracle.error <- (y.test - sum(ols.oracle*x.test.oracle))^2\n",
    "    \n",
    "    if(nrow(x.train)<=ncol(x.train)){\n",
    "        MSE.ols.error <- NaN\n",
    "        var.ols <- NaN\n",
    "    }else{\n",
    "        ols <- solve(t(scale(x.train))%*%scale(x.train))%*%(t(scale(x.train))%*%scale(y.train))\n",
    "        var.ols <- sum(ols != 0)\n",
    "        MSE.ols.error <- (y.test - sum(ols*x.test))^2  \n",
    "    }\n",
    "\n",
    "    list(MSE.lambda.ridge=MSE.lambda.ridge, MSE.lambda.lasso=MSE.lambda.lasso,  \n",
    "    MSE.ols.error=MSE.ols.error, MSE.ridge.error=MSE.ridge.error,\n",
    "    MSE.lasso.error= MSE.lasso.error, MSE.ols.oracle.error=MSE.ols.oracle.error,\n",
    "    var.ols=var.ols, var.ridge=var.ridge, var.lasso=var.lasso)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate <- function(Gamma=1, rho=0, alpha=0, obs=100, vars=10, spar=T, lambda.grid=lambda.grid){\n",
    "    \n",
    "    # This function simulates and estimates data for Gamma trials and saves the average MSE and \n",
    "    # number of selected variables across all trials\n",
    "    \n",
    "    MSE.ols.gamma <- c()\n",
    "    MSE.ridge.gamma <- c()\n",
    "    MSE.lasso.gamma <- c()\n",
    "    MSE.ols.oracle.gamma <- c()\n",
    "    var.ols.gamma <- c()\n",
    "    var.ridge.gamma <- c()\n",
    "    var.lasso.gamma <- c()\n",
    "    \n",
    "    for (gamma in (1:Gamma)){\n",
    "        model <- DGP(rho=rho, alpha=alpha, obs=obs, vars=vars, spar=spar)\n",
    "        result <- find.MSE(x=model$x, y=model$y, coef=model$coef, lambda.grid=lambda.grid)\n",
    "        MSE.ols.oracle.gamma[gamma] <- result$MSE.ols.oracle.error\n",
    "        MSE.ols.gamma[gamma] <- result$MSE.ols.error\n",
    "        MSE.ridge.gamma[gamma] <- result$MSE.ridge.error\n",
    "        MSE.lasso.gamma[gamma] <- result$MSE.lasso.error\n",
    "        var.ols.gamma[gamma] <- result$var.ols\n",
    "        var.ridge.gamma[gamma] <- result$var.ridge\n",
    "        var.lasso.gamma[gamma] <- result$var.lasso\n",
    "    }\n",
    "    \n",
    "    MSE.ols.oracle <- sum(MSE.ols.oracle.gamma)/Gamma\n",
    "    MSE.ols <- sum(MSE.ols.gamma)/Gamma\n",
    "    MSE.ridge <- sum(MSE.ridge.gamma)/Gamma\n",
    "    MSE.lasso <- sum(MSE.lasso.gamma)/Gamma\n",
    "    \n",
    "    list(MSE.ols.gamma=MSE.ols.gamma, MSE.ridge.gamma=MSE.ridge.gamma, MSE.lasso.gamma=MSE.lasso.gamma,\n",
    "        MSE.ols.oracle.gamma=MSE.ols.oracle.gamma, MSE.ols.oracle=MSE.ols.oracle,\n",
    "        MSE.ols=MSE.ols, MSE.ridge=MSE.ridge, MSE.lasso=MSE.lasso,\n",
    "        var.ols=sum(var.ols.gamma)/Gamma, var.ridge=sum(var.ridge.gamma)/Gamma, \n",
    "        var.lasso=sum(var.lasso.gamma)/Gamma)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Demonstration of one trial** <a class=\"anchor\" id=\"section_3_2\"></a>\n",
    "\n",
    "To demonstrate how the algorighm works I generate sparse data for one trial with no cross-sectional and no serial correlation and with 100 potential predictors. Afterwards, I apply the shrinkage methods and present the metric.\n",
    "First, I generate the data with the function DGP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "model <- DGP(rho=0, alpha=0, obs=100, vars=100, spar=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how the times series for the output variable look on the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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",
      "text/plain": [
       "Plot with title “Simulated time series of the output variable”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = seq(1, 100, length.out = 100)\n",
    "plot(T,model$y,type=\"l\",ylab = 'y', main = 'Simulated time series of the output variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I check the simulated series on stationary with the Augmented Dickey–Fuller (ADF) test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in adf.test(model$y):\n",
      "“p-value smaller than printed p-value”\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tAugmented Dickey-Fuller Test\n",
       "\n",
       "data:  model$y\n",
       "Dickey-Fuller = -4.7436, Lag order = 4, p-value = 0.01\n",
       "alternative hypothesis: stationary\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adf.test(model$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the series are indeed stationary. The same results holds for input variables. \n",
    "\n",
    "Then I run the estimation function for the tuning parameter grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda.grid <- seq(0.001, 0.3, length.out = 100)\n",
    "result <- find.MSE(model$x, model$y, model$coef, lambda.grid=lambda.grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the MSEs of ridge and lasso regressions for the each value of tuning parameter on grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\nACfxH1x6eHxQDTGuAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = data.frame(lambda.grid, ridge=result$MSE.lambda.ridge, lasso=result$MSE.lambda.lasso)\n",
    "dfplot <- df %>% gather(key, value, -lambda.grid)\n",
    "plot <- ggplot(dfplot, mapping = aes(x = lambda.grid, y = value, color = key) ) + geom_line()\n",
    "plot + ggtitle(\"MSE of ridge and lasso regressions for the different values of tuning parameter\") + \n",
    "xlab(\"grid of tuning parameter\") + ylab(\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal tuning parameter for ridge regression is 0.001 \n",
      "Optimal tuning parameter for lasso regression is 0.004 \n"
     ]
    }
   ],
   "source": [
    "cat(\"Optimal tuning parameter for ridge regression is\",\n",
    "    round(lambda.grid[which.min(result$MSE.lambda.ridge)],3),\"\\n\")\n",
    "cat(\"Optimal tuning parameter for lasso regression is\",\n",
    "    round(lambda.grid[which.min(result$MSE.lambda.lasso)],3),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSEs of the forecasts with the optimal values of tuning parameter for each method relative to the OLS oracle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of ols regression is NaN \n",
      "The MSE of ridge regression is 1.51 \n",
      "The MSE of lasso regression is 1.32 \n"
     ]
    }
   ],
   "source": [
    "cat(\"The MSE of ols regression is\",round(result$MSE.ols.error/result$MSE.ols.oracle.error, 3),\"\\n\")\n",
    "cat(\"The MSE of ridge regression is\",round(result$MSE.ridge.error/result$MSE.ols.oracle.error, 3),\"\\n\")\n",
    "cat(\"The MSE of lasso regression is\",round(result$MSE.lasso.error/result$MSE.ols.oracle.error, 3),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the value for the OLS regression is, obviously, unavailable because the number of regressors is equal to the number of observations in this specification. We also see that in this particular trial lasso outperforms ridge. That makes sense since the model is sparse.\n",
    "\n",
    "OLS and ridge include all ten variales to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of variables selected by ols regression NaN \n",
      "The number of variables selected by ridge regression 100 \n",
      "The number of variables selected by lasso regression 85 \n"
     ]
    }
   ],
   "source": [
    "cat(\"The number of variables selected by ols regression\",result$var.ols,\"\\n\")\n",
    "cat(\"The number of variables selected by ridge regression\",result$var.ridge,\"\\n\")\n",
    "cat(\"The number of variables selected by lasso regression\",result$var.lasso,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lasso performs the variable selection: it chooses 85 predictors. However, the true number of predictors is 5 so then more advanced technics such as adaptive lasso are necessary to improve the selection process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Sparsity and number of predictors effects** <a class=\"anchor\" id=\"section_3_3\"></a>\n",
    "\n",
    "To demonstrate how sparsity and number of predictors define the performance of ols, ridge and lasso regressions I generate and estimate the sparse and abundant models without cross-sectional and serial correlation for 10, 50 and 100 predictors 1000 times: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "spar.10 <- simulate(Gamma=1000, rho=0, alpha=0, obs=100, vars=10, spar=T, lambda.grid=lambda.grid)\n",
    "spar.50 <- simulate(Gamma=1000, rho=0, alpha=0, obs=100, vars=50, spar=T, lambda.grid=lambda.grid)\n",
    "spar.100 <- simulate(Gamma=1000, rho=0, alpha=0, obs=100, vars=100, spar=T, lambda.grid=lambda.grid)\n",
    "abun.10 <- simulate(Gamma=1000, rho=0, alpha=0, obs=100, vars=10, spar=F, lambda.grid=lambda.grid)\n",
    "abun.50 <- simulate(Gamma=1000, rho=0, alpha=0, obs=100, vars=50, spar=F, lambda.grid=lambda.grid)\n",
    "abun.100 <- simulate(Gamma=1000, rho=0, alpha=0, obs=100, vars=100, spar=F, lambda.grid=lambda.grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the table, I write the results to latex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct\n",
    "> simulation.sparsity <- matrix(c(spar.10$MSE.ols/spar.10$MSE.ols.oracle,spar.10$var.ols,\n",
    "                                  spar.50$MSE.ols/spar.50$MSE.ols.oracle,spar.50$var.ols,\n",
    "                                  spar.100$MSE.ols,spar.100$var.ols,\n",
    "                                  spar.10$MSE.ridge/spar.10$MSE.ols.oracle,spar.10$var.ridge,\n",
    "                                  spar.50$MSE.ridge/spar.50$MSE.ols.oracle,spar.50$var.ridge, \n",
    "                                  spar.100$MSE.ridge/spar.100$MSE.ols.oracle,spar.100$var.ridge,\n",
    "                                  spar.10$MSE.lasso/spar.10$MSE.ols.oracle,spar.10$var.lasso,\n",
    "                                  spar.50$MSE.lasso/spar.50$MSE.ols.oracle,spar.50$var.lasso,\n",
    "                                  spar.100$MSE.lasso/spar.100$MSE.ols.oracle,spar.100$var.lasso,\n",
    "                                  abun.10$MSE.ols/spar.10$MSE.ols.oracle,abun.10$var.ols,\n",
    "                                  abun.50$MSE.ols/spar.50$MSE.ols.oracle,abun.50$var.ols,\n",
    "                                  abun.100$MSE.ols,abun.100$var.ols,\n",
    "                                  abun.10$MSE.ridge/spar.10$MSE.ols.oracle,abun.10$var.ridge,\n",
    "                                  abun.50$MSE.ridge/spar.50$MSE.ols.oracle,abun.50$var.ridge,\n",
    "                                  abun.100$MSE.ridge/spar.100$MSE.ols.oracle,abun.100$var.ridge,\n",
    "                                  abun.10$MSE.lasso/spar.10$MSE.ols.oracle,abun.10$var.lasso,\n",
    "                                  abun.50$MSE.lasso/spar.50$MSE.ols.oracle,abun.50$var.lasso,\n",
    "                                  abun.100$MSE.lasso/spar.100$MSE.ols.oracle,abun.100$var.lasso), \n",
    "                                  nrow = 6, dimnames = list(c(\"MSE10\",\"var10\",\"MSE50\",\"var50\",\"MSE100\",\"var100\"),\n",
    "                                  c(\"sparols\",\"sparridge\",\"sparlasso\",\"abunols\",\"abunridge\",'abunlasso')))\n",
    "print(xtable(simulation.sparsity, digits=c(0,3,3,3,3,3,3), type = \"latex\"), \n",
    "      file = \"tex.files/simulation.sparsity.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt](images/simulation.sparsity.corrected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the specification with 10 predictors OLS, ridge and lasso almost don't differ in their performance in both sparse and abundant models. That confirms the conclusion that when the data is low-dimensional and, therefore, potential multicolinearity in the data is absent, then ridge and lasso, in general, do not show significantly better performance than OLS. Smeekes and Wijler (2018) additionally demonstrated that adaptive lasso and adaptive elastic net perform better than OLS in this setting. \n",
    "\n",
    "When we sequentially increase the number of predictors, the MSE increases too for both sparse and abundant models. This is so-called \"curse of dimensinality\": variance grows proportionally to the number of variables included in the model. However, the MSE increases significantly more for the abundant model. It is explained by the fact potential multicolinearity between the larger part of regressors that is associated with the response and the smaller part of the regressors which is not associated with the response complicates the identification of the effect of each predictor. Overall, the forecast for the abundant model would be less precise.\n",
    "\n",
    "Importantly, both specification with 50 and 100 predictors illustrate that, indeed, lasso outperforms ridge when the model is sparse and ridge outperforms lasso when the model is abundant. That happens because the lasso shrinks some of the coefficients exactly to zero and in the sparse model the large part of true coefficients are equal to zero. On the other hand, ridge shrinks the coefficients toward zero but never sets exactly to zero; and the large part of true coefficients in the abundant model is not zero.  \n",
    "\n",
    "We also see that lasso performs the variable selection. Not surprisingly, it selects less variables in the sparse model. However, this selection is far from being perfect: in sparse model the number of true predictors is 5 for every specification and in the abundant model I make it 6, 30 and 60 respectively. However, Smeekes and Wijler (2018) found a solution: they report that adaptive lasso and adaptive elastic net perform better variable selection. They also show that the selection is even more precise when BIC is used instead of CV procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4 Cross-sectional and serial correlation effects** <a class=\"anchor\" id=\"section_3_4\"></a>\n",
    "\n",
    "To analyze the cross-sectional and serial correlation effects I choose the specification with 50 potential predictors and simulate the trials for both sparse and abundant models varying th values for $p$ and $\\alpha$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {},
   "outputs": [],
   "source": [
    "spar.50.cross <- simulate(Gamma=1000, rho=0.6, alpha=0, obs=100, vars=50, spar=T, lambda.grid=lambda.grid)\n",
    "abun.50.cross <- simulate(Gamma=1000, rho=0.6, alpha=0, obs=100, vars=50, spar=F, lambda.grid=lambda.grid)\n",
    "spar.50.serial <- simulate(Gamma=1000, rho=0.6, alpha=0.6, obs=100, vars=50, spar=T, lambda.grid=lambda.grid)\n",
    "abun.50.serial <- simulate(Gamma=1000, rho=0.6, alpha=0.6, obs=100, vars=50, spar=F, lambda.grid=lambda.grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1551,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.correlation <- matrix(c(spar.50$MSE.ols/spar.50$MSE.ols.oracle,spar.50$var.ols, \n",
    "                        spar.50.cross$MSE.ols/spar.50.cross$MSE.ols.oracle,spar.50.cross$var.ols,\n",
    "                        spar.50.serial$MSE.ols/spar.50.serial$MSE.ols.oracle,spar.50.serial$var.ols,\n",
    "                        spar.50$MSE.ridge/spar.50$MSE.ols.oracle,spar.50$var.ridge,\n",
    "                        spar.50.cross$MSE.ridge/spar.50.cross$MSE.ols.oracle,spar.50.cross$var.ridge,\n",
    "                        spar.50.serial$MSE.ridge/spar.50.serial$MSE.ols.oracle,spar.50.serial$var.ridge,\n",
    "                        spar.50$MSE.lasso/spar.50$MSE.ols.oracle,spar.50$var.lasso, \n",
    "                        spar.50.cross$MSE.lasso/spar.50.cross$MSE.ols.oracle,spar.50.cross$var.lasso,\n",
    "                        spar.50.serial$MSE.lasso/spar.50.serial$MSE.ols.oracle,spar.50.serial$var.lasso,\n",
    "                        abun.50$MSE.ols/spar.50$MSE.ols.oracle,abun.50$var.ols, \n",
    "                        abun.50.cross$MSE.ols/spar.50.cross$MSE.ols.oracle, abun.50.cross$var.ols,\n",
    "                        abun.50.serial$MSE.ols/spar.50.serial$MSE.ols.oracle,abun.50.serial$var.ols,\n",
    "                        abun.50$MSE.ridge/spar.50$MSE.ols.oracle,abun.50$var.ridge,\n",
    "                        abun.50.cross$MSE.ridge/spar.50.cross$MSE.ols.oracle,abun.50.cross$var.ridge,\n",
    "                        abun.50.serial$MSE.ridge/spar.50.serial$MSE.ols.oracle,abun.50.serial$var.ridge,\n",
    "                        abun.50$MSE.lasso/spar.50$MSE.ols.oracle,abun.50$var.lasso, \n",
    "                        abun.50.cross$MSE.lasso/spar.50.cross$MSE.ols.oracle,abun.50.cross$var.lasso,\n",
    "                        abun.50.serial$MSE.lasso/spar.50.serial$MSE.ols.oracle,abun.50.serial$var.lasso), \n",
    "       nrow = 6, dimnames = list(c(\"MSEno\",\"varno\",\"MSEcross\",\"varcross\",\"MSEserial\",\"varserial\"), \n",
    "                                 c(\"sparols\",\"sparridge\",\"sparlasso\",\"abunols\",\"abunridge\",'abunlasso')))\n",
    "print(xtable(simulation.correlation, digits=c(0,3,3,3,3,3,3), type = \"latex\"), file = \"simulation.correlation.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt](images/simulation.correlation.corr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-sectional correlation does not significantly changes the picture for the sparse model: lasso is still sligthly ourperforms ridge; even though the MSE decreases more for ridge regression than for lasso. On the other hand, the MSE grows quite a lot in the abundant model underlining the fact that multicolinearity in the data is particularly dangerous when there are many true predictors of the response. Since the majority of relevant variables and few irrelevant variables might be correlated, it is more challenging to recognize the effect of each variable. Ridge is still a favorable method in this case. \n",
    "\n",
    "We observe that the introduction of serial correlation has little effect on the relative forecasting or selection performance of ridge and lasso: the trends described above also take place here. However, the variance of sparse and abundant models with autocorrelated errors tends to be lower which is a well-known fact in econometrics. If we ignore the serial correlation and estimate the variance the usual way, the variance estimator underestimates the true variance and the bias can be substantial. That justifies adding a lag/lags of a reponse variable to the model in the empirical application part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Empirical application <a class=\"anchor\" id=\"chapter4\"></a>\n",
    "\n",
    "To demonstrate the performance of ridge and lasso in macroeconomic forecasting I use [FRED Monthly Database for Macroeconomic Research](https://research.stlouisfed.org/econ/mccracken/fred-databases/) as the authors of the original paper Smeekes and Wijler (2018) do. Clearly, there exist a large number of publicly available macroeconomic databases (a comprehensive list of macroeconomic databases can be found on the [webpage](https://www.eui.eu/Research/Library/ResearchGuides/Economics/Statistics/MacroDataSet) of The European University Institute). A researcher can choose the one for her needs and apply the corresponding forecasting methods. FRED database presents 135 variables on a monthly basis beginning from 1959. The variables are organized in eight groups:  Output and income; Labor market; Housing; Consumption, orders, and inventories; Money and credit; Interest and exchange rates; Prices; Stock market. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Data preparation** <a class=\"anchor\" id=\"section_4_1\"></a>\n",
    "\n",
    "One of the advantages of using the FRED dataset is that it contains the information on the necessary transformation of the series to correct for stationarity. The tcode row for each series in the dataset denotes the following transformation of $x$: (1) not transformation; (2) $\\Delta x_t$; (3) $\\Delta^2 x_t$; (4) $log(x_t)$; (5) $\\Delta log(x_t)$; (6) $\\Delta^2 log(x_t)$; (7) $\\Delta (x_t/x_{t-1} - 1)$. To prepare the data for the estimation I remove the missing values and apply the transformation to the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in data.clean[, i]/c(0, data.clean[-nrow(data), i]):\n",
      "“longer object length is not a multiple of shorter object length”\n"
     ]
    }
   ],
   "source": [
    "#load the data and remove missing values\n",
    "data <- read.csv(\"data.csv\")\n",
    "dates <- as.matrix(data[3:(nrow(data)-1),1]) #2 less for later differencing\n",
    "data.raw <- data[1:(nrow(data)-1),-1]\n",
    "missing <- apply(data.raw,2,function(x){sum(is.na(x))})\n",
    "data.raw <- data.clean <- as.matrix(data.raw[,!missing>2])\n",
    "data.raw <- data.clean <- na.omit(data.raw)\n",
    "tcode <- data[1,-1][!missing>2]\n",
    "names<- colnames(data.raw)\n",
    "n <- nrow(data.clean)\n",
    "p <- ncol(data.clean)\n",
    "\n",
    "#correct for stationarity\n",
    "n2 <- nrow(data.clean)-2\n",
    "transformed <- vector()\n",
    "for(i in 1:length(tcode)){\n",
    "    if( tcode[i]==1){\n",
    "        tmp <- data.clean[,i]\n",
    "    }else if(tcode[i]==2){\n",
    "        tmp <- diff(data.clean[,i])\n",
    "    }else if(tcode[i]==3){\n",
    "        tmp <- diff(data.clean[,i],differences=2)\n",
    "    }else if(tcode[i]==4){\n",
    "        tmp <- log(data.clean[,i])\n",
    "    }else if(tcode[i]==5){\n",
    "        tmp <- diff(log(data.clean[,i]))\n",
    "    }else if(tcode[i]==6){\n",
    "        tmp <- diff(log(data.clean[,i]),differences=2)\n",
    "    }else if(tcode[i]==7){\n",
    "        tmp <- data.clean[,i]/c(0,data.clean[-nrow(data),i]) - 1\n",
    "    }\n",
    "    transformed <- cbind(transformed,tail(tmp,n2))\n",
    "}\n",
    "cleaned <- data.clean\n",
    "colnames(transformed) <- colnames(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Application** <a class=\"anchor\" id=\"section_4_2\"></a>\n",
    "\n",
    "I choose three series from different groups as response variables to showcase the forecasting performance of ridge and lasso: \n",
    "- Total Industrial Production from the group Output and income\n",
    "- Civilian Employment from the group Labor market\n",
    "- Real Personal Consumption Expenditures from the group Consumption, orders, and inventories\n",
    "- Effective Federal Funds Rate from the group Interest and exchange rates\n",
    "\n",
    "These series are similar to those frequently used in the forecasting literature (e.g. Kristensen (2017), Ludvigson and Ng (2009), Stock and Watson (2002b))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.names <- c(\"INDPRO\", \"CE16OV\", \"DPCERA3M086SBEA\", \"FEDFUNDS\")\n",
    "names <- c(\"Total Industrial Production\", \n",
    "           \"Civilian Employment\",\n",
    "           \"Real personal consumption expenditures\",\n",
    "          \"Effective Federal Funds Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I consider the following forecasting equation:\n",
    "\n",
    "$$y_{t+h} = \\alpha + x'_t \\beta_x + \\sum_{i=1}^p \\beta_i y_{t-i+1} + \\epsilon_{t+h}$$\n",
    "\n",
    "where $h$ is the forecasting horizon (I produce the forecast for the 6 months ahead); $x_t$ is the vector of all potential predictors; and $\\sum_{i=1}^p y_{t-i+1}$ are the lags of the response with the maximum length of 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "h <- 6 #Forecast horizon\n",
    "p.max <- 6 #Maximum number of AR lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the estimation I follow rolling window approach as in Smeekes and Wijler (2018). It means that an initial in-sample period covering 10 years of monthly observations ($window=120$) is used to estimate the models by which to obtain the first out-of-sample prediction. For each new prediction, we keep the length of the in-sample period fixed and move the estimation sample forward by one period. The number of optimal lags is determined by BIC. The optimal $\\lambda$ is determined by the CV and the test MSE. The parallel processing by clusters is used to shorten the time of running the code.\n",
    "\n",
    "I show the initial part of the code for the matter of demonstration and run the loop further in the section. The below algorithm is perfomed for each response variable of interest. The first step is to transform the whole dataset for a response variable such that it can have the matrix of independant variables for $[0:T]$ periods; the six lags of dependant variable for each of $[0:T]$ periods; and the vector of dependant variable for the periods $[h:T+h]$. Then we start the parallel forecast by applying the function **forecast** $f = T-window-h+1$ times:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create clusters and fix RNG seed\n",
    "\n",
    "    cl <- makeCluster(detectCores()-1)\n",
    "    clusterSetRNGStream(cl,iseed=2345678)\n",
    "    iter <- 0\n",
    "                    \n",
    "#Loop forecasts over different dependent variables\n",
    "\n",
    "     for(b in 1:length(var.names)){\n",
    "        iter <- iter+1\n",
    "    \n",
    "        #Obtain variables used for estimation\n",
    "        name <- y.name <- var.names[b]\n",
    "        y.ind <- which(colnames(cleaned)==name)\n",
    "        code <- tcode[y.ind]\n",
    "        y.tr <- transformed[,y.ind]\n",
    "        y.lags <- embed(y.tr,6)\n",
    "        x <- tail(transformed[,-y.ind],nrow(y.lags))\n",
    "        y.raw <- cleaned[,y.ind]\n",
    "        y.h <- y.tr[(p.max+h):length(y.tr)]\n",
    "        x <- head(x,length(y.h))\n",
    "\n",
    "        #start parallel forecast\n",
    "        varlist <- ls()\n",
    "        clusterSetRNGStream(cl,iseed=123457)\n",
    "        clusterExport(cl=cl,c(varlist,\"mvrnorm\",\"glmnet\",\"cv.glmnet\"))\n",
    "        f <- length(y.h)-window-h+1\n",
    "        output <- pblapply(1:f,forecast,cl=cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each $i$ from $f$ the function **forecast** determines training set as $[i:(i-1+window)]$ observations of the main dataset and test set as an observation in $h$ periods $(i-1+window+h)$. Then it estimates the coefficients on the training set by ridge and lasso; finds the number of optimal lags and the number of selected variables by lasso using the function **GLMN.emp**. As the final step, it derives the MSE using test observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast <- function(i){\n",
    "\n",
    "      #Define data sample\n",
    "      t <- window+h\n",
    "      x.train <- x[i:(i-1+window),]\n",
    "      y.l <- y.lags[i:(i-1+window),]\n",
    "      y.train <- y.h[i:(i-1+window)]\n",
    "      x.test <- x[i-1+t,]\n",
    "      y.test <- y.lags[i-1+t,]\n",
    "      y.f <- y.h[i-1+t]\n",
    "      n <- length(y.train)\n",
    "\n",
    "      #Define object to store results\n",
    "      pred <- vector()\n",
    "      MSE <- vector()\n",
    "      nvar <- vector()\n",
    "      lags <- vector()\n",
    "      coefs <- list()\n",
    "      names <- NULL\n",
    "      count <- 0\n",
    "\n",
    "      #shrinkage estimators\n",
    "      algos <- c(\"ridge\",\"las\")\n",
    "      ICs <- c(\"CV\")\n",
    "      for(j in 1:length(algos)){\n",
    "        for(i in 1:length(ICs)){\n",
    "          count <- count+1\n",
    "\n",
    "          #Define algorithm name and IC\n",
    "          name <- paste(algos[j],ICs[i],sep=\"\")\n",
    "          names <- c(names,name)\n",
    "\n",
    "          #Perform estimation\n",
    "          tmp <- GLMN.emp(y.train,x.train,y.l,type=algos[j],IC=ICs[i],IC.lag=\"BIC\")  \n",
    "          p <- tmp$lags\n",
    "          coef <- tmp$beta\n",
    "          yhat <- t(c(1,x.test,y.test[0:p]))%*%coef\n",
    "          pred[count] <- yhat\n",
    "          MSE[count] <- (y.f-yhat)^2\n",
    "          nvar[count] <- sum(as.logical(coef[-1]))\n",
    "          coefs[[count]] <- coef\n",
    "          lags[count] <- p\n",
    "          \n",
    "        }\n",
    "      }\n",
    "\n",
    "      #obtain output\n",
    "      results <- rbind(pred,MSE,nvar,lags)\n",
    "      colnames(results) <- names\n",
    "      list(results=results,coefs=coefs,actual=y.f)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the function **GLMN.emp** is to create a loop for each possible number of lags of the response variable, estimate the coefficients by the function **GLMN** and obtain the value of BIC by the function **get.IC** for each lag. Then it chooses the optimal number of lags by the lowest BIC and saves the respective vector of coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLMN.emp <- function(y,x,y.lags,type,IC,IC.lag){\n",
    "    ps <- 0:ncol(y.lags)\n",
    "    ICS <- vector()\n",
    "    betas <- list()\n",
    "    for(i in 1:length(ps)){\n",
    "        p <- ps[i]\n",
    "        x.tmp <- cbind(x,y.lags[,0:p])\n",
    "        beta <- GLMN(y,x.tmp,type=type,IC=IC,p=p)\n",
    "        betas[[i]] <- beta\n",
    "        ICS[i] <- get.IC(y,x.tmp,beta,IC=IC.lag,addint=T)\n",
    "    }\n",
    "    beta <- matrix(betas[[which.min(ICS)]],ncol=1)\n",
    "    lags <- ps[which.min(ICS)]\n",
    "    list(beta=beta,lags=lags)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **GLMN** divides our training set to the training and test observations again with the threshold $c_T$ introduced in the simulation part. It estimates the coefficients on the training observations either by ridge or lasso for the grid of $\\lambda$ values; applies the coefficients to the test observations; finds the predicted values of the response variable; and chooses the optimal $\\lambda$ by the minimal test MSE. Then it saves the vector of coefficients corresponding to the optimal $\\lambda$ for each method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLMN <- function(y,x,type=\"ridge\",IC=\"BIC\",p=0){\n",
    "    #normalize data\n",
    "    ys <- scale(y)\n",
    "    xs <- scale(x)\n",
    "    \n",
    "    if(type==\"las\"){\n",
    "      w <- rep(1,ncol(x))\n",
    "      if(p>0){\n",
    "        w[(length(w)-p+1):length(w)] <- 0\n",
    "      }\n",
    "        m <- ceiling((2/3)*nrow(x))\n",
    "        x.tr <- xs[1:m,]\n",
    "        y.tr <- ys[1:m]\n",
    "        x.te <- xs[(m+1):nrow(x),]\n",
    "        y.te <- ys[(m+1):nrow(x)]\n",
    "        glm <- glmnet(scale(x.tr),scale(y.tr),family=\"gaussian\",alpha=1-1e-6,penalty.factor = w)\n",
    "        coefs <- as.matrix(coef(glm))\n",
    "        lambdas <- as.numeric(glm$lambda)\n",
    "        y.pr <- cbind(rep(1,nrow(x.te)),x.te)%*%coefs\n",
    "        y.te <- matrix(rep(y.te,ncol(coefs)),length(y.te),ncol(coefs))\n",
    "        SFE <- (y.te-y.pr)^2\n",
    "        MSE <- colMeans(SFE)\n",
    "        lambda <- lambdas[which.min(MSE)]\n",
    "        beta <- coef(glmnet(xs,ys,family=\"gaussian\",alpha=1-1e-6,penalty.factor = w,lambda = lambda))\n",
    "        \n",
    "    }else if(type==\"ridge\"){\n",
    "      w <- rep(1,ncol(x))\n",
    "      if(p>0){\n",
    "        w[(length(w)-p+1):length(w)] <- 0\n",
    "      }\n",
    "        m <- ceiling((2/3)*nrow(x))\n",
    "        x.tr <- xs[1:m,]\n",
    "        y.tr <- ys[1:m]\n",
    "        x.te <- xs[(m+1):nrow(x),]\n",
    "        y.te <- ys[(m+1):nrow(x)]\n",
    "        glm <- glmnet(scale(x.tr),scale(y.tr),family=\"gaussian\",alpha=0,penalty.factor = w)\n",
    "        coefs <- as.matrix(coef(glm))\n",
    "        lambdas <- as.numeric(glm$lambda)\n",
    "        y.pr <- cbind(rep(1,nrow(x.te)),x.te)%*%coefs\n",
    "        y.te <- matrix(rep(y.te,ncol(coefs)),length(y.te),ncol(coefs))\n",
    "        SFE <- (y.te-y.pr)^2\n",
    "        MSE <- colMeans(SFE)\n",
    "        lambda <- lambdas[which.min(MSE)]\n",
    "        beta <- coef(glmnet(xs,ys,family=\"gaussian\",alpha=0,penalty.factor = w,lambda = lambda))\n",
    "    }\n",
    "    beta\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **get.IC** calculates the value of BIC either with or without intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "get.IC <- function(y,x,beta,IC=\"BIC\",addint=T){\n",
    "   \n",
    "     #Calculate variance\n",
    "    if(addint==T){\n",
    "        var <- sum((y-cbind(rep(1,nrow(x)),x)%*% beta)^2)/length(y)\n",
    "    }else{\n",
    "        var <- sum((y-x%*% beta)^2)/length(y)\n",
    "    }\n",
    "    \n",
    "    #Get IC\n",
    "    value <- log(var) + sum(beta!=0)*log(length(y))/length(y)\n",
    "    value\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, after the description of each function we can run the main loop of the empirical part. The function **forecast** saved the MSE, the selected number of variables and the optimal number of lags for every $i$. Now these values are averaged accross all $f$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Total Industrial Production\"\n",
      "       ridgeCV     lasCV\n",
      "MSE    1.00000 0.5305135\n",
      "nvar 123.64564 3.2504638\n",
      "lags   2.64564 1.7050093\n",
      "[1] \"Civilian Employment\"\n",
      "        ridgeCV    lasCV\n",
      "MSE    1.000000 1.736772\n",
      "nvar 124.046382 6.146568\n",
      "lags   3.046382 1.920223\n",
      "[1] \"Real personal consumption expenditures\"\n",
      "       ridgeCV     lasCV\n",
      "MSE    1.00000 0.8866497\n",
      "nvar 124.16141 5.0129870\n",
      "lags   3.16141 2.8998145\n",
      "[1] \"Effective Federal Funds Rate\"\n",
      "        ridgeCV    lasCV\n",
      "MSE    1.000000 1.011715\n",
      "nvar 122.779221 5.009276\n",
      "lags   1.779221 1.762523\n"
     ]
    }
   ],
   "source": [
    "#Create clusters and fix RNG seed\n",
    "cl <- makeCluster(detectCores()-1)\n",
    "clusterSetRNGStream(cl,iseed=2345678)\n",
    "iter <- 0\n",
    "                    \n",
    "#Loop forecasts over different dependent variables\n",
    "for(b in 1:length(var.names)){\n",
    "    iter <- iter+1\n",
    "    \n",
    "    #Obtain variables used for estimation\n",
    "    name <- y.name <- var.names[b]\n",
    "    y.ind <- which(colnames(cleaned)==name)\n",
    "    code <- tcode[y.ind]\n",
    "    y.tr <- transformed[,y.ind]\n",
    "    y.lags <- embed(y.tr,6)\n",
    "    x <- tail(transformed[,-y.ind],nrow(y.lags))\n",
    "    y.raw <- cleaned[,y.ind]\n",
    "    y.h <- y.tr[(p.max+h):length(y.tr)]\n",
    "    x <- head(x,length(y.h))\n",
    "    \n",
    "    #start parallel forecast\n",
    "    varlist <- ls()\n",
    "    clusterSetRNGStream(cl,iseed=123457)\n",
    "    clusterExport(cl=cl,c(varlist,\"mvrnorm\",\"glmnet\",\"cv.glmnet\"))\n",
    "    f <- length(y.h)-window-h+1\n",
    "    output <- pblapply(1:f,forecast,cl=cl)\n",
    "    results <- lapply(output,function(x){x[[1]]})\n",
    "    \n",
    "    #collect output\n",
    "    predictions <- t(sapply(results,function(x){x[1,]}))\n",
    "    sfes <- t(sapply(results,function(x){x[2,]}))\n",
    "    nvars <- t(sapply(results,function(x){x[3,]}))\n",
    "    lags <- t(sapply(results,function(x){x[4,]}))\n",
    "    actuals <- sapply(output,function(x){x$actual})\n",
    "    coefficients <- lapply(output,function(x){x$coefs})\n",
    "    result <- Reduce(\"+\",results)[-1,]/f\n",
    "    MSE <- result[1,]/result[1,1]\n",
    "    result <- rbind(MSE,result)\n",
    "    print(names[b])\n",
    "    print(result[c(1,3:4),])\n",
    "}\n",
    "                    \n",
    "stopCluster(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result, we obtain the MSE, the selected number of variables and the optimal number of lags by ridge and lasso for each variable. The lasso MSE is given relative to the ridge MSE. Unfortunately, I cannot compare the estimation results with OLS because the number of observations for each window is less than the number of potential predictors.\n",
    "\n",
    "We look at three different cases here: when ridge outperforms lasso; when lasso outperforms ridge; and when the MSE for two methods are relatively equal. It confirms the fact that the methods from shrinkage group might have different forecasting performance even within one dataset. Which method outperforms depends on the DGP of the response variables. Following the results in my simulation part, the sparsity and multi-colinearity in the data are among the factors that determine the precision of each method. Therefore, the recommendation for the researchers using shrinkage methods to forecast the macroeconomic environment would be not to focus on one of the them; but to compare the performance of few in different settings. The combination of methods will help to avoid unnecessary bias in the forecast and to obtain more precise results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion <a class=\"anchor\" id=\"chapter5\"></a>\n",
    "\n",
    "I performed an analysis of performance of shrinkage methods, in particular, of ridge and lasso regressions on macroecnomic forecasting. First, I explained why shrinkage methods is an appropriate tool for predicting macroeconomic outcomes: they reduce the variance in high-dimensional data setting by regularizing the coefficients estimates on the cost of estimates bias. Because of the differences in regularizing norms, which ridge and lasso employ, they also have different theoretical properties. Specifically, lasso shrinks some of the coefficients exactly to zero and ridge shrinks the coeficients toward zero but never sets them exactly to zero. This fact justifies that ridge and lasso outperform each other in settings with different DGP. \n",
    "\n",
    "I show in the realistic simulated macroeconomic setting that lasso outperforms ridge when only few of all predictors included to the model are associated with a response. On the other hand, ridge is more favorable when there is a large number of true predictors effecting the response. It is relevant for the increasing number of variables included to the model. I also demostrate that the forecast by ridge and lasso is less precise in case of the abundant model because of possible multicolinearity between relevant and irrelevant variables. Additionally, I confirm this fact by manually introducing multicolinearity to the data. Finally, I illustrate that including serirally correlated errors to the model does not effect the comparative perofrmance of ridge ad lasso, but, overall, it underestimates the variance in all specifications. \n",
    "\n",
    "In section 4 I apply ridge and lasso regressions in the empirical setting where we do not know the true DGP. I take a popular among macroeconomists dataset and implement few statistical technics to derive the ridge and lasso coefficients in the model with AR lags and to calculate the MSE of the forecast. I find that ridge and lasso outperform each other for different macroeconomic variables. Therefore, I conclude that an optimal strategy for macroeconomists would be not to choose one shrinkage method to perform the forecast; but to combine few methods and compare their performance. The area for the future research would be to add the other shrinkage methods and assess their performance in various time series settings such as non-stationary series, cointagrated variables, and VAR models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References <a class=\"anchor\" id=\"chapter6\"></a>\n",
    "\n",
    "- Bai, J. (2003). [Inferential theory for factor models of large dimensions](https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-0262.00392). *Econometrica, 71*(1), 135-171.\n",
    "- Bai, J. and Ng, S. (2006). [Confidence intervals for diffusion index forecasts and inference for factor‐augmented regressions](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00696.x).  *Econometrica, 74*(4), 1133-1150.\n",
    "- Bai, J. and Ng, S. (2001). [Determining the number of factors in approximate factor models](https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-0262.00273). *Econometrica, 70*(1),  191-221.\n",
    "- Basu, S., and Michailidis, G. (2015). [Regularized estimation in sparse high-dimensional time series models](https://www.jstor.org/stable/43556652?seq=1). *The Annals of Statistics, 43*(4), 1535-1567. \n",
    "- Beard, E., Brown, J., West, R., Kaner, E., Meier, P., Michie, S. (2019). [Associations between socio-economic factors and alcohol consumption: a population survey of adults in England](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0209442). *PLoS One, 14*(2).\n",
    "- Bucca, M., and Urbina, D. R. (2019). [Lasso regularization for selection of log-linear models: an application to educational assortative mating](https://journals.sagepub.com/doi/10.1177/0049124119826154#articleCitationDownloadContainer).* Sociological Methods & Research*.\n",
    "- Bühlmann, P., and van de Geer, S. (2011). [Theory for the lasso](https://link.springer.com/chapter/10.1007/978-3-642-20192-9_6#citeas). In: *Statistics for High-Dimensional Data. Springer Series in Statistics*. Springer, Berlin, Heidelberg.\n",
    "- Carriero, A., Galvao, A., and Kapetanios, G. (2016). [A comprehensive evaluation of macroeconomic forecasting methods](https://www.sciencedirect.com/science/article/abs/pii/S0169207019300731). *International Journal of Forecasting, 35*(4), 1226-1239.\n",
    "- Conniffe, D., Stone, J., and O'Neill, F. (1976). [Application of ridge regression in agricultural economics](https://www.jstor.org/stable/pdf/25556415.pdf?seq=1). *Irish Journal of Agricultural Economics and Rural Sociology, 6*(1), 89-92.\n",
    "- Coulombe, P., Stevanovic, D., and Surprenant, S. (2019). [How is machine learning useful for macroeconomic forecasting?](https://economics.sas.upenn.edu/system/files/2019-03/GCLSS_MC_MacroFcst.pdf) *CIRANO Working Papers* 2019s-22, CIRANO.\n",
    "- Ginestet, C.E. [Regularization: ridge regression and lasso](http://math.bu.edu/people/cgineste/classes/ma575/p/w14_1.pdf).  Lecture 2.\n",
    "- Goebl, C. S., Boykurt, L., Tura, A., Pacini, G., Kautzkz-Willer, A., and Mittlboeck, M. (2015). [Application of penalized regression techniques in modelling insulin sensitivity by correlated metabolic parameters](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141524). *PLoS ONE*.\n",
    "- Hall, A. (2018). [Machine learning approaches to macroeconomic forecasting](https://www.kansascityfed.org/~/media/files/publicat/econrev/econrevarchive/2018/4q18smalterhall.pdf). *Economic Review*, Federal Reserve Bank of Kansas City, issue Q IV, 63-81.\n",
    "- Hastie, T., Tibshirani, R., and Friedman, J. (2001). [The elements of statistical learning](https://web.stanford.edu/~hastie/ElemStatLearn/). *Springer New York Inc.*, New York, NY, USA.\n",
    "- Hoerl, A. and Kennard, R. (1970). [Ridge regression: biased estimation for nonorthogonal problems](https://www.tandfonline.com/doi/abs/10.1080/00401706.1970.10488634). *Technometrics, 12*, 55-67. \n",
    "- Huang, C. and Mintz, A. (1990). [Ridge regression analysis of the defence‐growth tradeoff in the United States](https://www.tandfonline.com/doi/abs/10.1080/10430719008404676). *Defence Economics, 2*, 29-37.\n",
    "- Hyndman, R.J., and Athanasopoulos, G. (2018) [Forecasting: principles and practice](OTexts.com/fpp2). *OTexts*, Melbourne, Australia.\n",
    "- Jain, R. (1985). [Ridge regression and its application to medical data](https://pubmed.ncbi.nlm.nih.gov/4042638/). *Computational Biomedical Ressearch, 18*(4), 363-368. \n",
    "- Jamal, N. and Rind, M. (2007). [Ridge regression: a tool to forecast wheat area and production](https://www.researchgate.net/publication/44286448_Ridge_Regression_A_tool_to_forecast_wheat_area_and_production). *Pakistan Journal of Statistics and Operation Research, 3*(2). \n",
    "- James, G., Witten, D., Hastie, T., and Tibshirani, R. (2014). [An introduction to statistical learning: with applications in R](https://dl.acm.org/doi/book/10.5555/2517747). *Springer New York Inc.*, New York, NY, USA.\n",
    "- Jean, N., Burke, M., Xie, M., Davis, W., Lobell, D., and Ermon, S. (2016). [Combining satellite imagery and machine learning to predict poverty](https://science.sciencemag.org/content/353/6301/790). *Science, 353*, 790-794. \n",
    "- Johnston, L. and Engelhardt, B. (2019). [Predicting crop yield and disease trends in central New Jersey farms](https://www.semanticscholar.org/paper/Predicting-Crop-Yield-and-Disease-Trends-in-Central-Johnston-Adviser/8cd0e88e5d3aa2f23e01ca09d7a0c376e91215c7). Working paper.\n",
    "- Kim, H. and Swanson, N. (2014). [Forecasting financial and macroeconomic variables using data reduction methods: New empirical evidence](https://www.sciencedirect.com/science/article/pii/S0304407613001978). SSRN Electronic Journal. 10.2139/ssrn.1856082. \n",
    "- Kock, A. and Callot, L. (2015). [Oracle inequalities for high dimensional vector autoregressions](https://www.sciencedirect.com/science/article/pii/S0304407615000378). *Journal of Econometrics, 186*(2), 325-344.\n",
    "- Kristensen, J.T. (2017). [Diffusion indexes with sparse loadings](https://www.tandfonline.com/doi/full/10.1080/07350015.2015.1084308). *Journal of Business & Economic Statistics, 35*, 434-451.\n",
    "- Ludvigson, S.C., and Ng, S. (2009). [A factor analysis of bond risk premia](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.416.108&rep=rep1&type=pdf). *National Bureau of Economic Research*, w15188.\n",
    "-  McCracken, M. W. and Ng, S. (2015). [FRED-MD: a monthly database for macroeconomic research](https://research.stlouisfed.org/wp/more/2015-012). *Working Papers 2015-12*, Federal Reserve Bank of St. Louis.\n",
    "- McKenzie, D. and Sansone, D. (2019). [Predicting entrepreneurial success is hard: Evidence from a business plan competition in Nigeria](https://www.sciencedirect.com/science/article/abs/pii/S0304387818305601?via%3Dihub). *Journal of Development Economics, 141*, 102369.\n",
    "- Medeiros, M. and Mendes, E. (2015). [L1-regularization of high-dimensional time-series models with non-Gaussian and heteroskedastic errors](https://www.sciencedirect.com/science/article/pii/S0304407615002638). *Journal of Econometrics, 191*(1), 255-271. \n",
    "- Mol, C., Giannone, D., and Reichlin, L. (2008). [Forecasting using a large number of predictors: is Bayesian shrinkage a valid alternative to principal components?](https://www.sciencedirect.com/science/article/pii/S0304407608001103). *Journal of Econometrics, 146*, 318-328. \n",
    "- Molina, M. and Garip, F. (2019). [Machine learning for sociology](https://www.annualreviews.org/doi/10.1146/annurev-soc-073117-041106). *Annual Review of Sociology, 45*, 27-45.\n",
    "- Mullainathan, S. and Spiess, J. (2017). [Machine learning: an applied econometric approach](https://www.aeaweb.org/articles?id=10.1257/jep.31.2.87). *Journal of Economic Perspectives, 31*(2), 87-106.\n",
    "- Ng, S. (2013). [Variable selection in predictive regressions](https://www.sciencedirect.com/science/article/pii/B9780444627315000142). *Handbook of Economic Forecasting*, in: G. Elliott, C. Granger,  A. Timmermann (ed.),Handbook of Economic Forecasting, 1(2), chapter 0, 752-789.\n",
    "- Ogutu, J., Schulz-Streeck, T., and Piepho, H. (2012). [Genomic selection using regularized linear regression models: ridge regression, lasso, elastic net and their extensions](https://www.semanticscholar.org/paper/Genomic-selection-using-regularized-linear-models%3A-Ogutu-Schulz-Streeck/9b6327dab2d0cb4b21489e0881ad4120a5b5149e). *BMC Proceedings, 6*, S10 - S10.\n",
    "- Pimentel, E., Queiroz, S., Carvalheiro, R., and Fries, L. (2007). [Use of ridge regression for the prediction of early growth performance in crossbred calves](https://www.scielo.br/scielo.php?script=sci_arttext&pid=S1415-47572007000400006). *Genetics and Molecular Biology, 30*(3).\n",
    "- Reiss, P. C. and Wolak, F.A. (2007). [Structural econometric modeling: rationales and examples from industrial organization](https://web.stanford.edu/group/fwolak/cgi-bin/sites/default/files/files/Structural%20Econometric%20Modeling_Rationales%20and%20Examples%20From%20Industrial%20Organization_Reiss%2C%20Wolak.pdf). *Handbook of Econometrics*, in: J.J. Heckman & E.E. Leamer (ed.),Handbook of Econometrics, 1(6), chapter 64. \n",
    "- Saleh, A., Arashi, M., and Kibria, B. (2019). [Theory of ridge regression estimation with applications](https://www.wiley.com/en-us/Theory+of+Ridge+Regression+Estimation+with+Applications-p-9781118644614). *John Wiley & Sons, Inc.*, Hoboken, NJ, USA.\n",
    "- Schneider, U. and Wagner, M. (2008). [Catching growth determinants with the adaptive LASSO](https://ideas.repec.org/p/ihs/ihsesp/232.html). *Economics Series 232*, Institute for Advanced Studies.\n",
    "- Singh, K., Singh, K.K., Kumar, S., Panwar, S., and Gurung, B. (2019). [Forecasting crop yield through weather indices through LASSO](https://www.researchgate.net/publication/332810158_Forecasting_crop_yield_through_weather_indices_through_LASSO). *Indian Journal of Agricultural Sciences, 89*, 540-544. \n",
    "- Smeekes, S., and Wijler, E. (2018). [Macroeconomic forecasting using penalized regression methods](https://www.sciencedirect.com/science/article/pii/S0169207018300074). International Journal of Forecasting, 34(3), 408-430.\n",
    "- Stock, J. H., and Watson, M. W. (2014). [Estimating turning points using large data sets](https://www.sciencedirect.com/science/article/abs/pii/S030440761300198X). *Journal of Econometrics, 178*(P2), 368-381.\n",
    "- Stock, J. H., and Watson, M. W. (2006). [Chapter 10. Forecasting with many predictors](https://www.sciencedirect.com/science/article/pii/S1574070605010104). *Handbook of Economic Forecasting, 1*, 515-554.\n",
    "- Stock, J. H., and Watson, M. W. (2002). [Forecasting using principal components from a large number of predictors](http://www.jstor.org/stable/3085839). *Journal of the American Statistical Association, 97*(460), 1167-1179. \n",
    "- Stock, J. H., and Watson, M. W. (1999). [Forecasting inflation](https://www.sciencedirect.com/science/article/abs/pii/S0304393299000276). *Journal of Monetary Economics, 44*(2), 293-335.\n",
    "- Theobald, C. (1974). [Generalizations of mean square error applied to ridge regression](https://www.jstor.org/stable/2984775?seq=1). *Journal of the Royal Statistical Society. Series B (Methodological), 36*(1), 103-106.\n",
    "- Tibshirani, R. (2012). [The Lasso problem and uniqueness](http://www.stat.cmu.edu/~ryantibs/papers/lassounique.pdf). *Electronic Journal of Statistics, 7*.\n",
    "- Tibshirani, R. (1996). [Regression shrinkage and selection via the lasso](https://www.jstor.org/stable/2346178?seq=1). *Journal of the Royal Statistical Society. Series B (Methodological), 58*(1), 267-288. \n",
    "- Tibshirani, R., and Taylor, J. (2011). [The solution path of the generalized lasso](https://projecteuclid.org/euclid.aos/1304514656). *Annals of Statistics, 39*(3), 1335-1371.\n",
    "- Vlaming, R. and Groenen, P. (2015). [The current and future use of ridge regression for prediction in quantitative genetics](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4529984/).\n",
    "- Wang, H., and Leng, C. (2007). [Unified LASSO estimation by least squares approximation](https://www.jstor.org/stable/27639944?seq=1). *Journal of the American Statistical Association, 102*(479), 1039-1048.\n",
    "- Wieringen, W. (2020a). [Lecture notes on lasso regression](http://www.few.vu.nl/~wvanwie/Courses/HighdimensionalDataAnalysis/WNvanWieringen_HDDA_Lecture56_LassoRegression_20182019.pdf). \n",
    "- Wieringen, W. (2020b). [Lecture notes on ridge regression](https://arxiv.org/pdf/1509.09169;Lecture).\n",
    "- Yunwen, R. and Xinsheng, Z. (2013). [Model selection for vector autoregressive processes via adaptive lasso](https://www.tandfonline.com/doi/abs/10.1080/03610926.2011.611317?needAccess=true&journalCode=lsta20). *Communications in Statistics - Theory and Methods, 42*(13), 2423-2436.\n",
    "- Zhang, J., Cavallari, J. M., Fang, S. C., Weisskopf, M. G., Lin, X., Mittleman, M. A., and Christiani, D. C. (2017). [Application of linear mixed-effects model with Lasso to identify metal components associated with cardiac autonomic responses among welders: a repeated measures study](https://pubmed.ncbi.nlm.nih.gov/28663305/). *Occupational and Environmental Medicine, 74*(11), 810-815."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
